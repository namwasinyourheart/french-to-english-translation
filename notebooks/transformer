{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSVr73yETCZDM+qQ0shbdd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"To9Jo5gs0Z9o","executionInfo":{"status":"ok","timestamp":1708269912456,"user_tz":-420,"elapsed":6198,"user":{"displayName":"Nam KHÔNG biết yêu bản thân mình!","userId":"09480669602647505283"}},"outputId":"acaa3b37-bdef-4561-8829-593e7c8fc39a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["# Model Define for Training\n","\"\"\" transformer \"\"\"\n","class Transformer(tf.keras.Model):\n","\n","    def __init__(self, n_enc_vocab, n_dec_vocab,\n","                 n_layers, pf_dim, hid_dim, n_heads,\n","                 pe_input, pe_target, dropout):\n","        super(Transformer, self).__init__()\n","        self.encoder = Encoder(n_enc_vocab,\n","                               n_layers, pf_dim, hid_dim, n_heads,\n","                               pe_input, dropout)\n","\n","        self.decoder = Decoder(n_dec_vocab,\n","                               n_layers, pf_dim, hid_dim, n_heads,\n","                               pe_target, dropout)\n","\n","        self.fin_output = tf.keras.layers.Dense(n_dec_vocab)\n","\n","    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n","\n","        # 1. \"inp\" is the encoder input of tokenized datasets\n","        # 2. \"enc_padding_mask\" are the self padding mask from encoder inputs\n","\n","        enc_output = self.encoder(inp, training, enc_padding_mask)\n","\n","        # 3. encoder outputs are created from encoder model and it is given to the \"Key\" and \"Value\" of Multi-Head Attention 2 of decoder layers\n","        # 4. \"tar\" is the Decoder input of tokenized datasets. It is not a final output.\n","        # 5. \"look_ahead_mask\" are created from decoder inputs, it is given to the \"Key\" and \"Value\" of Multi-Head Attention 1.\n","        # 6. \"dec_padding_mask\" are the self padding mask from encoder inputs\n","\n","        dec_output, attention_weights = self.decoder(\n","            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n","\n","        # 7. decoder output is creadted from decoder model\n","\n","        final_output = self.fin_output(dec_output)\n","\n","        # 8. Final outputs are created. Then it is used or Language Model. In the official tutorial \"Softmax\"  was missed.\n","\n","        return final_output, attention_weights\n"],"metadata":{"id":"o2sX3uEX0fZH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\" encoder layer \"\"\"\n","class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, pf_dim, hid_dim, n_heads, dropout):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.attn = MultiHeadAttentionLayer(hid_dim, n_heads)\n","        self.ffn = PositionwiseFeedforwardLayer(hid_dim, pf_dim)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(dropout)\n","        self.dropout2 = tf.keras.layers.Dropout(dropout)\n","\n","    def call(self, inputs, training, padding_mask):\n","\n","        # 1. Encoder mutihead attention is defined.\n","        attention, _ = self.attn(inputs, inputs, inputs, padding_mask)  # (batch_size, input_seq_len, hid_dim)\n","        attention   = self.dropout1(attention, training=training)\n","\n","        # 2. 1 st residual layer.\n","        attention   = self.layernorm1(inputs + attention)  # (batch_size, input_seq_len, hid_dim)\n","\n","        # 3. Feed Forward Network\n","        ffn_outputs = self.ffn(attention)  # (batch_size, input_seq_len, hid_dim)\n","\n","        ffn_outputs = self.dropout2(ffn_outputs, training=training)\n","\n","        # 4. 2 nd residual layer.\n","        ffn_outputs = self.layernorm2(attention + ffn_outputs)  # (batch_size, input_seq_len, hid_dim)\n","\n","        # 5. encoder output of each encoder layer\n","        return ffn_outputs\n"],"metadata":{"id":"nRdoiG7m0l0L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\" encoder \"\"\"\n","class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, n_enc_vocab, n_layers, pf_dim, hid_dim, n_heads,\n","                 maximum_position_encoding, dropout):\n","        super(Encoder, self).__init__()\n","\n","        self.hid_dim  = hid_dim\n","        self.n_layers = n_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(n_enc_vocab, hid_dim)\n","        self.pos_encoding = get_sinusoid_encoding_table(maximum_position_encoding,\n","                                                self.hid_dim)\n","\n","        self.enc_layers = [EncoderLayer(pf_dim, hid_dim, n_heads, dropout)\n","                           for _ in range(n_layers)]\n","\n","        self.dropout1 = tf.keras.layers.Dropout(dropout)\n","\n","    def call(self, x, training, padding_mask):\n","        seq_len = tf.shape(x)[1]\n","\n","        # adding embedding and position encoding.\n","        # 1. Token Embedding\n","        emb = self.embedding(x)  # (batch_size, input_seq_len, hid_dim)\n","        emb *= tf.math.sqrt(tf.cast(self.hid_dim, tf.float32))\n","\n","        # 2. Sinusoidal positional Encoding\n","        emb += self.pos_encoding[:, :seq_len, :]\n","\n","        output = self.dropout1(emb, training=training)\n","\n","        # 3. Self padding Mask is created from encoder input\n","\n","        # 4. Encoder layers are stacked.\n","        for i in range(self.n_layers):\n","            output = self.enc_layers[i](output, training, padding_mask)\n","\n","        # 5. Final layer's output is the encoder output.\n","\n","        return output  # (batch_size, input_seq_len, hid_dim)\n"],"metadata":{"id":"UukFulOQ0nGi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n","      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n","  ])\n","\n","d_model = 128\n","dff = 512\n","batch_size = 64\n","input_seq_len = 37\n","\n","sample_input = tf.ones((batch_size, input_seq_len, d_model))\n","print(sample_input.shape)\n"],"metadata":{"id":"zeChbg1R0piB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_ffn = point_wise_feed_forward_network(d_model, dff)\n","sample_ffn.build(sample_input.shape)\n","sample_ffn.summary()\n"],"metadata":{"id":"i1IUUVzv0qfX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Q2E25Aqyq3cz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"acz8wnB1q7F6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"3TS-k0Gyq65N","executionInfo":{"status":"ok","timestamp":1708502286364,"user_tz":-420,"elapsed":7145,"user":{"displayName":"Nam KHÔNG biết yêu bản thân mình!","userId":"09480669602647505283"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["\"\"\" attention pad mask \"\"\"\n","def create_padding_mask(seq):\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","    # (batch_size, 1, 1, key의 문장 길이)\n","    return seq[:, tf.newaxis, tf.newaxis, :]\n","\n","\"\"\" attention decoder mask \"\"\"\n","def create_look_ahead_mask(size):\n","    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","    return mask\n","\n","def create_masks(inp, tar):\n","    enc_padding_mask = create_padding_mask(inp)\n","    dec_padding_mask = create_padding_mask(inp)\n","\n","    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","    dec_target_padding_mask = create_padding_mask(tar)\n","    look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","\n","    return enc_padding_mask, look_ahead_mask, dec_padding_mask\n"],"metadata":{"id":"esjr1q1qq30Q","executionInfo":{"status":"ok","timestamp":1708502266643,"user_tz":-420,"elapsed":9,"user":{"displayName":"Nam KHÔNG biết yêu bản thân mình!","userId":"09480669602647505283"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","def create_padding_mask(seq):\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","    # Add extra dimensions to add the padding to the attention logits.\n","    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n","\n","def create_look_ahead_mask(size):\n","    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","    return mask  # (seq_len, seq_len)\n","\n","def create_masks(inp, tar):\n","    # Encoder padding mask\n","    enc_padding_mask = create_padding_mask(inp)\n","\n","    # Decoder padding mask\n","    dec_padding_mask = create_padding_mask(inp)\n","\n","    # Look-ahead mask\n","    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","    dec_target_padding_mask = create_padding_mask(tar)\n","    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","\n","    return enc_padding_mask, combined_mask, dec_padding_mask\n","\n"],"metadata":{"id":"eaDBdIDfq4Jw","executionInfo":{"status":"ok","timestamp":1708502948602,"user_tz":-420,"elapsed":313,"user":{"displayName":"Nam KHÔNG biết yêu bản thân mình!","userId":"09480669602647505283"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\n","# Example sequences with length 3 and embedding dimension 5\n","input_sequence = tf.constant([[1, 2, 0, 0, 0], [3, 4, 5, 0, 0], [6, 0, 0, 0, 0]])\n","target_sequence = tf.constant([[1, 2, 3, 0, 0], [4, 5, 6, 0, 0], [7, 8, 0, 0, 0]])\n","\n","enc_padding_mask, combined_mask, dec_padding_mask = create_masks(input_sequence, target_sequence)\n","\n","print(\"Encoder Padding Mask:\")\n","print(enc_padding_mask)\n","\n","print(\"\\nDecoder Padding Mask:\")\n","print(dec_padding_mask)\n","\n","print(\"\\nCombined Mask (Look-ahead Mask + Decoder Padding Mask):\")\n","print(combined_mask)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NYjo0MtMtHam","executionInfo":{"status":"ok","timestamp":1708502951163,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nam KHÔNG biết yêu bản thân mình!","userId":"09480669602647505283"}},"outputId":"f8bc3471-8ce6-4bd2-d5d6-d0d9ab973516"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoder Padding Mask:\n","tf.Tensor(\n","[[[[0. 0. 1. 1. 1.]]]\n","\n","\n"," [[[0. 0. 0. 1. 1.]]]\n","\n","\n"," [[[0. 1. 1. 1. 1.]]]], shape=(3, 1, 1, 5), dtype=float32)\n","\n","Decoder Padding Mask:\n","tf.Tensor(\n","[[[[0. 0. 1. 1. 1.]]]\n","\n","\n"," [[[0. 0. 0. 1. 1.]]]\n","\n","\n"," [[[0. 1. 1. 1. 1.]]]], shape=(3, 1, 1, 5), dtype=float32)\n","\n","Combined Mask (Look-ahead Mask + Decoder Padding Mask):\n","tf.Tensor(\n","[[[[0. 1. 1. 1. 1.]\n","   [0. 0. 1. 1. 1.]\n","   [0. 0. 0. 1. 1.]\n","   [0. 0. 0. 1. 1.]\n","   [0. 0. 0. 1. 1.]]]\n","\n","\n"," [[[0. 1. 1. 1. 1.]\n","   [0. 0. 1. 1. 1.]\n","   [0. 0. 0. 1. 1.]\n","   [0. 0. 0. 1. 1.]\n","   [0. 0. 0. 1. 1.]]]\n","\n","\n"," [[[0. 1. 1. 1. 1.]\n","   [0. 0. 1. 1. 1.]\n","   [0. 0. 1. 1. 1.]\n","   [0. 0. 1. 1. 1.]\n","   [0. 0. 1. 1. 1.]]]], shape=(3, 1, 5, 5), dtype=float32)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Pq09McNdtiIN"},"execution_count":null,"outputs":[]}]}